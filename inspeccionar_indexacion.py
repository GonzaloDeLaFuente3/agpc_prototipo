#!/usr/bin/env python3
"""
Inspecciona qu√© texto se index√≥ REALMENTE en ChromaDB para casos de amparo.
"""

import sys
sys.path.append('.')

from agent.semantica import coleccion, modelo_embeddings
import json
import os

print("="*80)
print("INSPECCI√ìN DE INDEXACI√ìN - CASOS DE AMPARO")
print("="*80)

# Variables globales
conversaciones_amparo = []
fragmentos_amparo = []

# 1. Buscar el dataset en varias ubicaciones posibles
print("\n1Ô∏è‚É£ BUSCANDO DATASET...")
posibles_rutas = [
    'legal_dataset_200.json',
    'data/legal_dataset_200.json',
    'datasets/legal_dataset_200.json',
    '../legal_dataset_200.json'
]

dataset_path = None
for ruta in posibles_rutas:
    if os.path.exists(ruta):
        dataset_path = ruta
        break

if dataset_path:
    print(f"‚úÖ Dataset encontrado en: {dataset_path}")
    try:
        with open(dataset_path, 'r', encoding='utf-8') as f:
            dataset = json.load(f)
        
        conversaciones = dataset.get('conversaciones', [])
        print(f"‚úÖ Dataset cargado: {len(conversaciones)} conversaciones")
        
        # Buscar conversaciones con "amparo por mora"
        for i, conv in enumerate(conversaciones):
            contenido = conv.get('contenido', '')
            if 'amparo por mora' in contenido.lower():
                conversaciones_amparo.append({
                    'index': i,
                    'titulo': conv.get('titulo', 'Sin t√≠tulo'),
                    'contenido': contenido,
                    'contenido_completo': contenido
                })
        
        print(f"‚úÖ Encontradas {len(conversaciones_amparo)} conversaciones con 'amparo por mora'")
        
        if conversaciones_amparo:
            print(f"\nüìã Primera conversaci√≥n de amparo (ORIGINAL):")
            print(f"   T√≠tulo: {conversaciones_amparo[0]['titulo']}")
            print(f"   Contenido completo ({len(conversaciones_amparo[0]['contenido'])} caracteres):")
            print(f"   {conversaciones_amparo[0]['contenido'][:500]}...")
            print()
        
    except Exception as e:
        print(f"‚ùå Error cargando dataset: {e}")
        import traceback
        traceback.print_exc()
else:
    print(f"‚ö†Ô∏è Dataset no encontrado en ubicaciones conocidas")
    print(f"   Rutas buscadas:")
    for ruta in posibles_rutas:
        print(f"   - {ruta}")
    print(f"\n   Continuando con an√°lisis de ChromaDB...")

# 2. Buscar en ChromaDB los fragmentos indexados con "amparo"
print("\n2Ô∏è‚É£ INSPECCIONANDO FRAGMENTOS INDEXADOS EN CHROMADB...")
try:
    all_docs = coleccion.get(include=['documents', 'metadatas'])
    
    for i, (id, doc, meta) in enumerate(zip(
        all_docs['ids'], 
        all_docs['documents'],
        all_docs.get('metadatas', [{}] * len(all_docs['ids']))
    )):
        if 'amparo' in doc.lower():
            fragmentos_amparo.append({
                'id': id,
                'texto': doc,
                'longitud': len(doc),
                'metadata': meta
            })
    
    print(f"‚úÖ Encontrados {len(fragmentos_amparo)} fragmentos con 'amparo' en ChromaDB")
    
    if fragmentos_amparo:
        print(f"\nüìã Primeros 5 fragmentos indexados:")
        for i, frag in enumerate(fragmentos_amparo[:5], 1):
            print(f"\n   {i}. ID: {frag['id'][:40]}")
            print(f"      Longitud: {frag['longitud']} caracteres")
            print(f"      Metadata: {frag['metadata']}")
            print(f"      Texto completo:")
            print(f"      '{frag['texto']}'")
            print()
            
            # AN√ÅLISIS DEL FRAGMENTO
            if frag['longitud'] < 100:
                print(f"      ‚ö†Ô∏è FRAGMENTO MUY CORTO (<100 chars)")
            
            if 'amparo por mora' in frag['texto'].lower():
                print(f"      ‚úÖ Contiene 'amparo por mora' completo")
            else:
                print(f"      ‚ö†Ô∏è NO contiene 'amparo por mora' completo")
    else:
        print(f"‚ùå NO se encontraron fragmentos con 'amparo'")
        print(f"   Esto indica que el dataset NO se carg√≥ o se limpi√≥ ChromaDB")
    
except Exception as e:
    print(f"‚ùå Error: {e}")
    import traceback
    traceback.print_exc()

# 3. An√°lisis de longitud de fragmentos
print("\n3Ô∏è‚É£ AN√ÅLISIS DE LONGITUD DE FRAGMENTOS")
print("-"*80)

if fragmentos_amparo:
    longitudes = [f['longitud'] for f in fragmentos_amparo]
    print(f"Estad√≠sticas de longitud:")
    print(f"  M√≠nimo: {min(longitudes)} caracteres")
    print(f"  M√°ximo: {max(longitudes)} caracteres")
    print(f"  Promedio: {sum(longitudes)/len(longitudes):.0f} caracteres")
    
    # Contar fragmentos cortos
    muy_cortos = sum(1 for l in longitudes if l < 100)
    cortos = sum(1 for l in longitudes if 100 <= l < 200)
    normales = sum(1 for l in longitudes if l >= 200)
    
    print(f"\nDistribuci√≥n:")
    print(f"  Muy cortos (<100 chars): {muy_cortos} ({muy_cortos/len(longitudes)*100:.1f}%)")
    print(f"  Cortos (100-200 chars): {cortos} ({cortos/len(longitudes)*100:.1f}%)")
    print(f"  Normales (>200 chars): {normales} ({normales/len(longitudes)*100:.1f}%)")
    
    if muy_cortos > len(longitudes) * 0.5:
        print(f"\n‚ö†Ô∏è PROBLEMA CR√çTICO: >50% de fragmentos son muy cortos")
        print(f"   ‚Üí Los embeddings tendr√°n baja calidad")
        print(f"   ‚Üí Necesitas revisar la fragmentaci√≥n en agent/fragmentador.py")

# 4. Probar b√∫squeda con diferentes queries
print("\n4Ô∏è‚É£ PRUEBA DE B√öSQUEDAS CON DIFERENTES QUERIES")
print("-"*80)

queries = [
    "Amparo por mora administrativa",
    "amparo por mora",
    "amparo",
    "mora administrativa",
    "presentar amparo"
]

for query in queries:
    try:
        print(f"\nüìç Query: '{query}'")
        emb = modelo_embeddings.encode(query)
        resultado = coleccion.query(
            query_embeddings=[emb.tolist()],
            n_results=5,
            include=['documents', 'distances']
        )
        
        print("   Top 5 resultados:")
        for i, (doc, dist) in enumerate(zip(
            resultado['documents'][0],
            resultado['distances'][0]
        ), 1):
            tiene_amparo = '‚úÖ' if 'amparo' in doc.lower() else '‚ùå'
            print(f"   {i}. {tiene_amparo} Dist: {dist:.4f}")
            print(f"      {doc[:100]}...")
        
    except Exception as e:
        print(f"   ‚ùå Error: {e}")

# 5. Comparar con dataset original si est√° disponible
if conversaciones_amparo and fragmentos_amparo:
    print("\n5Ô∏è‚É£ COMPARACI√ìN: ORIGINAL vs INDEXADO")
    print("-"*80)
    
    print("\nüìÑ CONVERSACI√ìN ORIGINAL:")
    print(f"  Longitud: {len(conversaciones_amparo[0]['contenido_completo'])} caracteres")
    print(f"  Texto completo:")
    print(f"  {conversaciones_amparo[0]['contenido_completo'][:400]}...")
    
    print("\nüì¶ FRAGMENTOS INDEXADOS DE ESTA CONVERSACI√ìN:")
    # Buscar fragmentos que puedan corresponder a esta conversaci√≥n
    fragmentos_relacionados = [f for f in fragmentos_amparo 
                               if 'test_' not in f['id']]  # Excluir casos de test
    
    if fragmentos_relacionados:
        print(f"  Encontrados {len(fragmentos_relacionados)} fragmentos (excluyendo tests)")
        for i, frag in enumerate(fragmentos_relacionados[:3], 1):
            print(f"\n  Fragmento {i}:")
            print(f"    Longitud: {frag['longitud']} caracteres")
            print(f"    Texto: {frag['texto'][:200]}...")
    else:
        print(f"  ‚ö†Ô∏è No se encontraron fragmentos (solo hay casos de test)")

print("\n" + "="*80)
print("FIN DE LA INSPECCI√ìN")
print("="*80)

# DIAGN√ìSTICO FINAL
print("\nüìä DIAGN√ìSTICO FINAL:")
print("-"*80)

if not fragmentos_amparo:
    print("‚ùå PROBLEMA CR√çTICO: No hay fragmentos de 'amparo' en ChromaDB")
    print("   SOLUCI√ìN: Necesitas cargar el dataset con:")
    print("   python cargar_dataset_limpio.py")

elif all('test_' in f['id'] for f in fragmentos_amparo):
    print("‚ö†Ô∏è ADVERTENCIA: Solo hay casos de TEST en ChromaDB")
    print("   Los casos de test funcionan bien (como vimos antes)")
    print("   SOLUCI√ìN: Necesitas cargar el dataset real con:")
    print("   python cargar_dataset_limpio.py")

elif fragmentos_amparo:
    muy_cortos = sum(1 for f in fragmentos_amparo if f['longitud'] < 100)
    if muy_cortos > len(fragmentos_amparo) * 0.5:
        print("‚ùå PROBLEMA: Fragmentos muy cortos")
        print("   Los fragmentos son demasiado cortos para buenos embeddings")
        print("   SOLUCI√ìN: Modificar agent/fragmentador.py para fragmentos m√°s largos")
    else:
        print("‚úÖ Fragmentos tienen longitud aceptable")
        print("   SOLUCI√ìN: El problema puede estar en el √≠ndice HNSW")
        print("   Prueba reindexar con: python cargar_dataset_limpio.py")

print("\nüí° RECOMENDACI√ìN:")
print("   1. Borra ChromaDB y datos: rmdir /s /q chroma_db && rmdir /s /q data")
print("   2. Reinicia servidor: python main.py")  
print("   3. Carga dataset: python cargar_dataset_limpio.py")
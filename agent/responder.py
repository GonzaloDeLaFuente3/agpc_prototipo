# agent/responder.py 
import requests
import os
from datetime import datetime
from typing import Dict
import google.generativeai as genai


GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 

if not GEMINI_API_KEY:
    raise ValueError("‚ùå ERROR: No se encontr√≥ GEMINI_API_KEY en el archivo .env")

genai.configure(api_key=GEMINI_API_KEY)

def construir_prompt(pregunta: str, contextos: dict) -> str:
    """
    Construye prompt optimizado para respuestas temporales y documentos.
    - Distingue entre fragmentos de conversaciones y documentos
    - Instrucciones claras sobre uso de contextos
    - Informaci√≥n temporal expl√≠cita
    - Manejo de fragmentos relacionados
    - Detecci√≥n de preguntas de enumeraci√≥n 
    - Indicaci√≥n de cantidad de contextos disponibles
    """
    
    #  Contar contextos disponibles
    num_contextos = len(contextos)
    
    # Detectar si la pregunta es temporal 
    es_pregunta_temporal = any(palabra in pregunta.lower() for palabra in [
        'ma√±ana', 'ayer', 'hoy', 'semana', 'mes', 'lunes', 'martes', 
        'mi√©rcoles', 'jueves', 'viernes', 's√°bado', 'domingo',
        'cuando', 'cu√°ndo', 'qu√© d√≠a', 'fecha'
    ])
    
    #  Detectar si la pregunta pide enumeraci√≥n
    es_pregunta_enumeracion = any(palabra in pregunta.lower() for palabra in [
        'qu√© casos', 'cu√°les', 'cu√°ntos', 'qu√© reuniones', 'qu√© proyectos',
        'qu√© documentos', 'lista', 'todos los', 'cu√°les son', 'enumera',
        'menciona todos', 'qu√© temas', 'qu√© conversaciones'
    ])
    
    # Clasificar contextos por tipo
    fragmentos_documentos = []
    fragmentos_conversaciones = []
    tiene_timestamps = False
    
    for id, c in contextos.items():
        titulo = c.get('titulo', 'Sin t√≠tulo')
        texto = c.get('texto', '')
        timestamp = c.get('timestamp')
        es_pdf = c.get('es_pdf', False)
        tipo_contexto = c.get('tipo_contexto', 'general')
        
        # Clasificar por tipo
        if es_pdf or tipo_contexto == 'documento':
            # Es un fragmento de documento
            source_doc = c.get('source_document', 'documento')
            posicion = c.get('position_in_doc', 0)
            total_frags = c.get('total_fragmentos_pdf', 1)
            
            fragmentos_documentos.append({
                'titulo': f"üìÑ {source_doc} (parte {posicion+1}/{total_frags})",
                'texto': texto,
                'timestamp': timestamp
            })
        else:
            # Es un fragmento de conversaci√≥n
            if timestamp:
                tiene_timestamps = True
                try:
                    fecha = datetime.fromisoformat(timestamp.replace('Z', ''))
                    fecha_str = fecha.strftime('%d/%m/%Y %H:%M')
                    titulo_formateado = f"üìÖ [{fecha_str}] {titulo}"
                except:
                    titulo_formateado = f"üí¨ {titulo}"
            else:
                titulo_formateado = f"üí¨ {titulo}"
            
            fragmentos_conversaciones.append({
                'titulo': titulo_formateado,
                'texto': texto,
                'timestamp': timestamp
            })
    
    # Construir secciones del prompt
    secciones = []
    
    if fragmentos_documentos:
        docs_formateados = []
        for frag in fragmentos_documentos:
            docs_formateados.append(f"{frag['titulo']}:\n{frag['texto']}")
        
        secciones.append(f"""**DOCUMENTOS RELEVANTES:**
{chr(10).join(docs_formateados)}""")
    
    if fragmentos_conversaciones:
        convs_formateadas = []
        for frag in fragmentos_conversaciones:
            convs_formateadas.append(f"{frag['titulo']}:\n{frag['texto']}")
        
        secciones.append(f"""**CONVERSACIONES RELEVANTES:**
{chr(10).join(convs_formateadas)}""")
    
    # Construir prompt seg√∫n tipo de pregunta
    if es_pregunta_temporal and tiene_timestamps:
        # CASO 1: Pregunta TEMPORAL
        prompt = f"""Eres un asistente experto que ayuda a responder preguntas sobre eventos, conversaciones, actividades programadas y documentos.

**PREGUNTA DEL USUARIO:**
"{pregunta}"

**CONTEXTOS DISPONIBLES ({num_contextos} contextos en total):**
{chr(10).join(secciones)}

**INSTRUCCIONES IMPORTANTES:**
1. Se te proporcionan {num_contextos} contextos con informaci√≥n relevante
2. La pregunta tiene componente TEMPORAL - prioriza fechas y horarios
3. Si hay M√öLTIPLES eventos/casos/documentos, menci√≥nalos TODOS de forma agrupada
4. Sintetiza informaci√≥n com√∫n entre los contextos
5. Incluye fechas y horarios cuando est√©n disponibles
6. Si los contextos son fragmentos relacionados, comb√≠nalos en una respuesta coherente

**FORMATO DE RESPUESTA:**
- Si hay m√∫ltiples casos/eventos: Indica cu√°ntos encontraste y enum√©ralos de forma concisa
- Agrupa por patrones comunes cuando sea posible
- S√© completo pero evita redundancias

**RESPUESTA:**"""

    elif es_pregunta_enumeracion:
        # CASO 2: Pregunta de ENUMERACI√ìN 
        prompt = f"""Eres un asistente experto en an√°lisis y s√≠ntesis de informaci√≥n legal y documental.

**PREGUNTA DEL USUARIO:**
"{pregunta}"

**CONTEXTOS DISPONIBLES ({num_contextos} contextos en total):**
{chr(10).join(secciones)}

**INSTRUCCIONES CR√çTICAS:**
1. Se te proporcionan {num_contextos} contextos relevantes
2. La pregunta pide una ENUMERACI√ìN o LISTA de elementos
3. Debes mencionar TODOS los casos/documentos/elementos encontrados
4. NO te limites solo al primer contexto - sintetiza TODOS
5. Agrupa por patrones comunes si existen (ej: "8 casos de Amparo por mora administrativa")
6. S√© completo pero conciso - evita repetir la misma informaci√≥n

**FORMATO DE RESPUESTA ESPERADO:**
- Primero: Indica el total encontrado y el patr√≥n com√∫n si existe
- Luego: Enumera los elementos de forma concisa (ej: "Casos 1, 2, 3, 4, 5, 6, 7 y 8")
- Finalmente: Menciona caracter√≠sticas comunes relevantes

**EJEMPLO DE BUENA RESPUESTA:**
"Durante [periodo] se discutieron 8 casos de [tipo] (Casos 1, 2, 3, 4, 5, 6, 7 y 8). Todos estos casos comparten [caracter√≠sticas comunes]."

**RESPUESTA:**"""

    else:
        # CASO 3: Pregunta GENERAL (explicaci√≥n, concepto, etc.) 
        prompt = f"""Eres un asistente experto que ayuda a explicar y responder sobre contenido de documentos y conversaciones.

**PREGUNTA:**
"{pregunta}"

**CONTEXTOS DISPONIBLES ({num_contextos} contextos en total):**
{chr(10).join(secciones)}

**INSTRUCCIONES CR√çTICAS - LEE CON ATENCI√ìN:**
1. Se te proporcionan {num_contextos} contextos relevantes para responder
2. **DEBES ANALIZAR Y USAR TODOS LOS {num_contextos} CONTEXTOS** en tu respuesta
3. Si varios contextos contienen casos o ejemplos similares, MENCI√ìNALOS TODOS de forma concisa
4. Si encuentras m√∫ltiples casos/documentos relacionados, AGR√öPALOS y haz una s√≠ntesis clara
5. NO te limites solo al primer contexto - tu respuesta debe reflejar el an√°lisis completo de todos los contextos
6. Si los contextos son fragmentos del mismo tema, comb√≠nalos en una respuesta coherente

**FORMATO DE RESPUESTA ESPERADO:**
- Si hay m√∫ltiples casos/documentos similares: "Se encontraron {num_contextos} casos relacionados: [lista breve o agrupaci√≥n]"
- Si hay informaci√≥n com√∫n en varios contextos: "Los contextos mencionan como patr√≥n com√∫n: [s√≠ntesis]"
- Si son fragmentos relacionados: Integra la informaci√≥n en p√°rrafos coherentes sin repetir

**EJEMPLO DE BUENA RESPUESTA:**
Si la pregunta es "¬øQu√© casos se discutieron?" y tienes 8 contextos de "Amparo por mora":
"Se encontraron 8 casos de Amparo por mora administrativa (Casos 1, 2, 3, 4, 5, 6, 7 y 8). Todos comparten el patr√≥n de que el proceso es r√°pido (30-60 d√≠as) y el Estado debe cumplir las √≥rdenes judiciales bajo amenaza de multas."

**RESPUESTA:**"""
    
    return prompt


def responder_con_ia(pregunta: str, contextos: dict) -> str:
    """
    Genera respuesta usando Google Gemini con prompt optimizado.
    """
    if not GEMINI_API_KEY:
        return "[ERROR] No se configur√≥ GEMINI_API_KEY"
    
    if not contextos:
        return "No se encontraron contextos relevantes para responder tu pregunta."
    
    prompt = construir_prompt(pregunta, contextos)
    
    # Usar SDK de Google en lugar de requests
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # Configuraci√≥n  (igual que RAG est√°ndar)
        generation_config = {
            'temperature': 0.3,
            'top_p': 0.95,
            'top_k': 40,
            'max_output_tokens': 2048
        }
        
        response = model.generate_content(
            prompt,
            generation_config=generation_config
        )
        
        respuesta = response.text.strip()
        
        # Post-procesamiento: remover frases problem√°ticas comunes
        frases_problematicas = [
            "la informaci√≥n provista no",
            "los fragmentos no mencionan",
            "no se proporciona informaci√≥n",
            "no hay informaci√≥n sobre"
        ]
        
        if any(frase in respuesta.lower() for frase in frases_problematicas):
            print(f"‚ö†Ô∏è Respuesta problem√°tica detectada: {respuesta[:100]}")
            
            if contextos:
                primer_contexto = list(contextos.values())[0]
                titulo = primer_contexto.get('titulo', 'contexto')
                timestamp = primer_contexto.get('timestamp')
                
                if timestamp:
                    try:
                        fecha = datetime.fromisoformat(timestamp.replace('Z', ''))
                        fecha_str = fecha.strftime('%d/%m a las %H:%M')
                        return f"Encontr√© informaci√≥n relacionada en '{titulo}' programado para el {fecha_str}."
                    except:
                        return f"Encontr√© informaci√≥n relacionada en '{titulo}'."
                else:
                    return f"Encontr√© informaci√≥n relacionada en '{titulo}'."
        
        return respuesta
        
    except Exception as e:
        return f"[ERROR] {str(e)}"
# agent/fragmentador.py
import uuid
import re
from datetime import datetime
from typing import List, Dict, Tuple
from agent.extractor import extraer_palabras_clave

def criterio_fragmentacion_semantica(texto: str, max_palabras: int = 150) -> List[str]:
    """
    Fragmenta una conversaci칩n en bloques sem치nticamente coherentes.
    
    Criterios de fragmentaci칩n:
    1. Cambios de hablante (si se detectan patrones como "Juan:", "- Mar칤a:")
    2. P치rrafos largos (m치s de max_palabras)
    3. Cambios de tema (detecci칩n b치sica por puntos/cambios abruptos)
    4. Separadores expl칤citos (l칤neas con "---", "***", etc.)
    """
    if not texto or not texto.strip():
        return []
    
    # Normalizar texto
    texto = texto.strip()
    
    # 1. Dividir por separadores expl칤citos primero
    separadores_explicitos = re.split(r'\n[-*=]{3,}\n|\n\s*[-*=]{3,}\s*\n', texto)
    
    fragmentos_finales = []
    
    for bloque in separadores_explicitos:
        bloque = bloque.strip()
        if not bloque:
            continue
            
        # 2. Detectar cambios de hablante
        # Patrones: "Nombre:", "- Nombre:", "[Timestamp] Nombre:"
        patron_hablante = r'^(\s*-?\s*[A-Z츼칄칈칍칔][a-z치칠칤칩칰침\s]+:|^\[\d+:\d+\]\s*[A-Z츼칄칈칍칔][a-z치칠칤칩칰침\s]+:)'
        
        lineas = bloque.split('\n')
        fragmento_actual = []
        
        for linea in lineas:
            linea = linea.strip()
            if not linea:
                continue
                
            # Si detectamos cambio de hablante y ya tenemos contenido, crear fragmento
            if re.match(patron_hablante, linea) and fragmento_actual:
                texto_fragmento = '\n'.join(fragmento_actual).strip()
                if len(texto_fragmento.split()) > 10:  # M칤nimo 10 palabras
                    fragmentos_finales.extend(_dividir_por_tama침o(texto_fragmento, max_palabras))
                fragmento_actual = [linea]
            else:
                fragmento_actual.append(linea)
        
        # Agregar 칰ltimo fragmento del bloque
        if fragmento_actual:
            texto_fragmento = '\n'.join(fragmento_actual).strip()
            if len(texto_fragmento.split()) > 10:
                fragmentos_finales.extend(_dividir_por_tama침o(texto_fragmento, max_palabras))
    
    # Si no se encontraron patrones especiales, fragmentar por p치rrafos y tama침o
    if not fragmentos_finales:
        fragmentos_finales = _dividir_por_parrafos_y_tama침o(texto, max_palabras)
    
    # Limpieza final
    return [f.strip() for f in fragmentos_finales if f.strip() and len(f.split()) >= 5]

def _dividir_por_tama침o(texto: str, max_palabras: int) -> List[str]:
    """Divide un texto por tama침o m치ximo de palabras, respetando frases completas."""
    palabras = texto.split()
    
    if len(palabras) <= max_palabras:
        return [texto]
    
    fragmentos = []
    inicio = 0
    
    while inicio < len(palabras):
        fin = min(inicio + max_palabras, len(palabras))
        
        # Buscar punto final cercano para corte natural
        if fin < len(palabras):
            for i in range(fin, max(inicio + int(max_palabras * 0.7), inicio + 10), -1):
                if i < len(palabras) and palabras[i-1].endswith('.'):
                    fin = i
                    break
        
        fragmento = ' '.join(palabras[inicio:fin])
        fragmentos.append(fragmento)
        inicio = fin
    
    return fragmentos

def _dividir_por_parrafos_y_tama침o(texto: str, max_palabras: int) -> List[str]:
    """Divisi칩n por p치rrafos con control de tama침o."""
    parrafos = [p.strip() for p in texto.split('\n\n') if p.strip()]
    
    if not parrafos:
        parrafos = [p.strip() for p in texto.split('\n') if p.strip()]
    
    fragmentos = []
    fragmento_actual = []
    palabras_actuales = 0
    
    for parrafo in parrafos:
        palabras_parrafo = len(parrafo.split())
        
        if palabras_actuales + palabras_parrafo <= max_palabras:
            fragmento_actual.append(parrafo)
            palabras_actuales += palabras_parrafo
        else:
            # Guardar fragmento actual
            if fragmento_actual:
                fragmentos.append('\n\n'.join(fragmento_actual))
            
            # Si el p치rrafo es muy largo, dividirlo
            if palabras_parrafo > max_palabras:
                fragmentos.extend(_dividir_por_tama침o(parrafo, max_palabras))
                fragmento_actual = []
                palabras_actuales = 0
            else:
                fragmento_actual = [parrafo]
                palabras_actuales = palabras_parrafo
    
    # Agregar 칰ltimo fragmento
    if fragmento_actual:
        fragmentos.append('\n\n'.join(fragmento_actual))
    
    return fragmentos

def fragmentar_conversacion(conversacion: Dict) -> List[Dict]:
    """
    Toma una conversaci칩n completa y la fragmenta autom치ticamente.
    
    Args:
        conversacion: {
            'titulo': str,
            'contenido': str, 
            'fecha': str (ISO),
            'participantes': list,
            'metadata': dict
        }
    
    Returns:
        Lista de fragmentos con metadatos
    """
    contenido = conversacion.get('contenido', '').strip()
    if not contenido:
        return []
    
    # Obtener fragmentos de texto
    textos_fragmentos = criterio_fragmentacion_semantica(contenido)
    
    fragmentos_con_metadata = []
    conversacion_id = str(uuid.uuid4())
    
    for i, texto_fragmento in enumerate(textos_fragmentos):
        fragmento_id = str(uuid.uuid4())
        
        # Detectar si el fragmento tiene informaci칩n temporal individual
        referencias_temporales = []
        palabras_clave = extraer_palabras_clave(texto_fragmento)
        
        # Heredar timestamp de la conversaci칩n o detectar individual
        timestamp_fragmento = conversacion.get('fecha')
        
        # Crear metadatos del fragmento
        metadata_fragmento = {
            "fragmento_id": fragmento_id,
            "conversacion_id": conversacion_id,
            "conversacion_titulo": conversacion.get('titulo', 'Sin t칤tulo'),
            "posicion_en_conversacion": i + 1,
            "total_fragmentos_conversacion": len(textos_fragmentos),
            "texto": texto_fragmento,
            "palabras_clave": palabras_clave,
            "timestamp": timestamp_fragmento,
            "participantes": conversacion.get('participantes', []),
            "metadata_conversacion": conversacion.get('metadata', {}),
            "created_at": datetime.now().isoformat(),
            "es_temporal": bool(timestamp_fragmento),
            "tipo_contexto": _detectar_tipo_fragmento(texto_fragmento, conversacion.get('metadata', {}))
        }
        
        fragmentos_con_metadata.append({
            'id': fragmento_id,
            'metadata': metadata_fragmento
        })
    
    return fragmentos_con_metadata

def _detectar_tipo_fragmento(texto: str, metadata_conversacion: Dict) -> str:
    """Detecta el tipo de fragmento basado en contenido y contexto de conversaci칩n."""
    texto_lower = texto.lower()
    
    # Si la conversaci칩n ya tiene tipo, heredarlo como base
    tipo_base = metadata_conversacion.get('tipo', 'general')
    
    # Patrones espec칤ficos de fragmentos
    patrones_especificos = {
        "decision": ["decidimos", "acordamos", "resolveremos", "la decisi칩n", "se decidi칩"],
        "accion": ["hacer", "implementar", "ejecutar", "realizar", "completar"],
        "pregunta": ["", "como", "c칩mo", "qu칠", "cu치ndo", "d칩nde", "por qu칠"],
        "conclusion": ["en resumen", "para concluir", "finalmente", "en conclusi칩n"],
        "problema": ["problema", "issue", "bug", "error", "falla", "no funciona"]
    }
    
    for tipo, palabras in patrones_especificos.items():
        if any(palabra in texto_lower for palabra in palabras):
            return tipo
    
    return tipo_base

# Funci칩n de utilidad para testing
def test_fragmentacion():
    """Funci칩n de testing para validar la fragmentaci칩n."""
    texto_test = """
    Juan: Hola equipo, vamos a revisar el estado del proyecto.
    
    Mar칤a: Perfecto Juan. He completado la implementaci칩n del m칩dulo de usuario. 
    Todo funciona correctamente y ya est치 listo para testing.
    
    Pedro: Excelente Mar칤a. Por mi parte, he encontrado algunos problemas con la 
    base de datos. Espec칤ficamente, las consultas est치n tomando demasiado tiempo.
    
    Juan: 쯈u칠 propones Pedro para solucionarlo?
    
    Pedro: Creo que necesitamos optimizar los 칤ndices y revisar algunas queries.
    Tambi칠n podr칤amos implementar cache para las consultas m치s frecuentes.
    
    ---
    
    DECISIONES TOMADAS:
    1. Mar칤a continuar치 con el testing del m칩dulo de usuario
    2. Pedro se enfocar치 en la optimizaci칩n de la base de datos
    3. Pr칩xima reuni칩n: viernes a las 15:00
    """
    
    conversacion_test = {
        'titulo': 'Reuni칩n de Proyecto - Revisi칩n Semanal',
        'contenido': texto_test,
        'fecha': '2025-01-25T10:00:00',
        'participantes': ['Juan', 'Mar칤a', 'Pedro'],
        'metadata': {'tipo': 'reunion', 'proyecto': 'Sistema Web', 'duracion': '30min'}
    }
    
    fragmentos = fragmentar_conversacion(conversacion_test)
    
    print(f"游댌 Testing de Fragmentaci칩n:")
    print(f"Conversaci칩n: {conversacion_test['titulo']}")
    print(f"Total fragmentos generados: {len(fragmentos)}\n")
    
    for i, frag in enumerate(fragmentos, 1):
        print(f"--- Fragmento {i} ---")
        print(f"ID: {frag['id']}")
        print(f"Tipo: {frag['metadata']['tipo_contexto']}")
        print(f"Palabras clave: {frag['metadata']['palabras_clave'][:5]}")
        print(f"Texto: {frag['metadata']['texto'][:100]}...")
        print()
    
    return fragmentos

if __name__ == "__main__":
    test_fragmentacion()
# agent/dataset_loader.py
import json
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from agent.fragmentador import fragmentar_conversacion

class DatasetLoader:
    """Cargador de datasets JSON para testing y demos masivos."""
    
    FORMATO_ESPERADO = {
        "dominio": "nombre_del_dominio",
        "metadata": {
            "descripcion": "DescripciÃ³n del dataset",
            "fecha_creacion": "ISO timestamp", 
            "autor": "Autor del dataset",
            "version": "1.0",
            "tags": ["tag1", "tag2"]
        },
        "conversaciones": [
            {
                "titulo": "Nombre conversaciÃ³n",
                "contenido": "Texto completo...",
                "fecha": "ISO timestamp",
                "participantes": ["lista"],
                "metadata": {
                    "tipo": "reunion|entrevista|brainstorm|planning|general",
                    "duracion": "30min",
                    "proyecto": "Nombre proyecto",
                    "prioridad": "alta|media|baja"
                }
            }
        ]
    }
    
    def __init__(self):
        self.estadisticas = {
            'conversaciones_procesadas': 0,
            'fragmentos_generados': 0,
            'errores': [],
            'tiempo_inicio': None,
            'tiempo_fin': None
        }
    
    def validar_formato(self, dataset: Dict) -> Tuple[bool, List[str]]:
        """Valida que el dataset tenga el formato correcto."""
        errores = []
        
        # Validar campos obligatorios del dataset
        if 'dominio' not in dataset:
            errores.append("Falta campo obligatorio: 'dominio'")
        
        if 'conversaciones' not in dataset:
            errores.append("Falta campo obligatorio: 'conversaciones'")
        elif not isinstance(dataset['conversaciones'], list):
            errores.append("El campo 'conversaciones' debe ser una lista")
        elif len(dataset['conversaciones']) == 0:
            errores.append("La lista de conversaciones estÃ¡ vacÃ­a")
        
        # Validar cada conversaciÃ³n
        for i, conv in enumerate(dataset.get('conversaciones', [])):
            if not isinstance(conv, dict):
                errores.append(f"ConversaciÃ³n {i+1}: debe ser un objeto")
                continue
            
            if 'titulo' not in conv:
                errores.append(f"ConversaciÃ³n {i+1}: falta campo 'titulo'")
            
            if 'contenido' not in conv:
                errores.append(f"ConversaciÃ³n {i+1}: falta campo 'contenido'")
            elif not conv['contenido'].strip():
                errores.append(f"ConversaciÃ³n {i+1}: contenido vacÃ­o")
            
            # Validar formato de fecha si existe
            if 'fecha' in conv and conv['fecha']:
                try:
                    datetime.fromisoformat(conv['fecha'].replace('Z', '+00:00'))
                except (ValueError, AttributeError):
                    errores.append(f"ConversaciÃ³n {i+1}: formato de fecha invÃ¡lido (usar ISO 8601)")
            
            # Validar participantes
            if 'participantes' in conv and not isinstance(conv['participantes'], list):
                errores.append(f"ConversaciÃ³n {i+1}: 'participantes' debe ser una lista")
        
        return len(errores) == 0, errores
    
    def procesar_dataset(self, dataset: Dict, sobrescribir: bool = False) -> Dict:
        """
        Procesa un dataset completo y carga todas las conversaciones.
        
        Args:
            dataset: Diccionario con el formato esperado
            sobrescribir: Si True, permite sobreescribir datos existentes
            
        Returns:
            EstadÃ­sticas del procesamiento
        """
        self.estadisticas = {
            'conversaciones_procesadas': 0,
            'fragmentos_generados': 0,
            'errores': [],
            'tiempo_inicio': datetime.now(),
            'tiempo_fin': None,
            'dominio': dataset.get('dominio', 'desconocido'),
            'conversaciones_fallidas': []
        }
        
        # Validar formato
        es_valido, errores_validacion = self.validar_formato(dataset)
        if not es_valido:
            self.estadisticas['errores'].extend(errores_validacion)
            self.estadisticas['tiempo_fin'] = datetime.now()
            return self.estadisticas
        
        print(f"Iniciando carga masiva del dominio: {dataset['dominio']}")
        print(f"Conversaciones a procesar: {len(dataset['conversaciones'])}")
        
        # Procesar cada conversaciÃ³n
        from agent.grafo import agregar_conversacion
        
        for i, conversacion_data in enumerate(dataset['conversaciones'], 1):
            try:
                print(f"Procesando {i}/{len(dataset['conversaciones'])}: {conversacion_data['titulo'][:50]}...")
                
                # Preparar metadatos enriquecidos
                metadata = conversacion_data.get('metadata', {}).copy()
                metadata.update({
                    'dominio': dataset['dominio'],
                    'dataset_metadata': dataset.get('metadata', {}),
                    'posicion_en_dataset': i,
                    'cargado_masivamente': True
                })
                
                # Agregar conversaciÃ³n usando el sistema existente
                resultado = agregar_conversacion(
                    titulo=conversacion_data['titulo'],
                    contenido=conversacion_data['contenido'],
                    fecha=conversacion_data.get('fecha'),
                    participantes=conversacion_data.get('participantes', []),
                    metadata=metadata
                )
                
                self.estadisticas['conversaciones_procesadas'] += 1
                self.estadisticas['fragmentos_generados'] += resultado['total_fragmentos']
                
                if i % 5 == 0:  # Progress cada 5 conversaciones
                    print(f"    âœ… Progreso: {i}/{len(dataset['conversaciones'])} conversaciones procesadas")
                
            except Exception as e:
                error_msg = f"Error procesando conversaciÃ³n {i} '{conversacion_data.get('titulo', 'Sin tÃ­tulo')}': {str(e)}"
                print(f"    âŒ {error_msg}")
                self.estadisticas['errores'].append(error_msg)
                self.estadisticas['conversaciones_fallidas'].append({
                    'posicion': i,
                    'titulo': conversacion_data.get('titulo', 'Sin tÃ­tulo'),
                    'error': str(e)
                })
        
        self.estadisticas['tiempo_fin'] = datetime.now()
        duracion = (self.estadisticas['tiempo_fin'] - self.estadisticas['tiempo_inicio']).total_seconds()
        
        print(f"\nCarga masiva completada:")
        print(f"Conversaciones procesadas: {self.estadisticas['conversaciones_procesadas']}")
        print(f"Fragmentos generados: {self.estadisticas['fragmentos_generados']}")
        print(f"Errores: {len(self.estadisticas['errores'])}")
        print(f"Tiempo total: {duracion:.2f} segundos")
        
        if self.estadisticas['errores']:
            print(f"Errores encontrados:")
            for error in self.estadisticas['errores'][:3]:  # Mostrar primeros 3
                print(f"- {error}")
            if len(self.estadisticas['errores']) > 3:
                print(f"... y {len(self.estadisticas['errores'])-3} errores mÃ¡s")
        
        return self.estadisticas
    
    def cargar_desde_archivo(self, ruta_archivo: str, sobrescribir: bool = False) -> Dict:
        """Carga un dataset desde archivo JSON."""
        try:
            with open(ruta_archivo, 'r', encoding='utf-8') as f:
                dataset = json.load(f)
            
            return self.procesar_dataset(dataset, sobrescribir)
            
        except FileNotFoundError:
            return {
                'errores': [f"Archivo no encontrado: {ruta_archivo}"],
                'conversaciones_procesadas': 0,
                'fragmentos_generados': 0
            }
        except json.JSONDecodeError as e:
            return {
                'errores': [f"Error parseando JSON: {str(e)}"],
                'conversaciones_procesadas': 0,
                'fragmentos_generados': 0
            }
        except Exception as e:
            return {
                'errores': [f"Error inesperado: {str(e)}"],
                'conversaciones_procesadas': 0,
                'fragmentos_generados': 0
            }
    
    def generar_dataset_ejemplo(self, nombre_dominio: str = "ejemplo_reuniones") -> Dict:
        """Genera un dataset de ejemplo para testing."""
        return {
            "dominio": nombre_dominio,
            "metadata": {
                "descripcion": "Dataset de ejemplo con reuniones de equipo",
                "fecha_creacion": datetime.now().isoformat(),
                "autor": "Sistema AGPC",
                "version": "1.0",
                "tags": ["ejemplo", "reuniones", "testing"]
            },
            "conversaciones": [
                {
                    "titulo": "ReuniÃ³n Semanal de Producto - Sprint 23",
                    "contenido": """Juan: Buenos dÃ­as equipo, empezamos la retrospectiva del Sprint 23.
                    
MarÃ­a: Hola Juan. Esta semana completÃ© la implementaciÃ³n del login social. Todo estÃ¡ funcionando correctamente con Google y Facebook.

Pedro: Perfecto MarÃ­a. Por mi parte, tuve algunos problemas con la optimizaciÃ³n de la base de datos. Las consultas siguen siendo lentas.

Juan: Â¿QuÃ© propones Pedro?

Pedro: Creo que necesitamos implementar indexaciÃ³n en las tablas principales y revisar las queries mÃ¡s complejas. Estimo que me tomarÃ¡ 2 dÃ­as.

Ana: Yo terminÃ© el diseÃ±o de la nueva landing page. Ya estÃ¡ lista para implementaciÃ³n. Â¿Pedro, podrÃ­as ayudarme con la integraciÃ³n la prÃ³xima semana?

Pedro: Claro Ana, sin problema.

---

DECISIONES TOMADAS:
1. MarÃ­a continÃºa con testing del login social
2. Pedro se enfoca en optimizaciÃ³n DB (2 dÃ­as)
3. Ana e integration de landing page para la prÃ³xima semana
4. PrÃ³xima reuniÃ³n: jueves 15:00""",
                    "fecha": "2025-01-22T09:00:00",
                    "participantes": ["Juan", "MarÃ­a", "Pedro", "Ana"],
                    "metadata": {
                        "tipo": "reunion",
                        "duracion": "45min",
                        "proyecto": "Plataforma Web",
                        "prioridad": "alta"
                    }
                },
                {
                    "titulo": "Brainstorm - Nuevas Funcionalidades Q2",
                    "contenido": """Facilitador: Bienvenidos al brainstorm de funcionalidades para Q2. Tenemos 1 hora para generar ideas.

Participante1: Propongo implementar un sistema de notificaciones push mÃ¡s inteligente, que aprenda de los hÃ¡bitos del usuario.

Participante2: Me gusta esa idea. TambiÃ©n creo que necesitamos un dashboard mÃ¡s personalizable, donde cada usuario pueda organizar sus widgets.

Participante3: Â¿QuÃ© tal si agregamos integraciÃ³n con herramientas de productividad como Slack y Trello?

Facilitador: Excelentes ideas. Â¿Alguien mÃ¡s?

Participante1: TambiÃ©n podrÃ­amos implementar un modo offline mÃ¡s robusto.

Participante2: SÃ­, y quizÃ¡s un sistema de colaboraciÃ³n en tiempo real como Google Docs.

---

IDEAS PRIORIZADAS:
1. Notificaciones inteligentes (MVP)
2. Dashboard personalizable (MVP)  
3. IntegraciÃ³n Slack/Trello (Nice to have)
4. Modo offline mejorado (Technical debt)
5. ColaboraciÃ³n tiempo real (Future)""",
                    "fecha": "2025-01-20T14:00:00",
                    "participantes": ["Facilitador", "Participante1", "Participante2", "Participante3"],
                    "metadata": {
                        "tipo": "brainstorm",
                        "duracion": "60min",
                        "proyecto": "Plataforma Web",
                        "prioridad": "media"
                    }
                },
                {
                    "titulo": "Entrevista TÃ©cnica - Desarrollador Senior",
                    "contenido": """Entrevistador: Hola, gracias por venir. Soy el Lead Developer del equipo. Â¿PodrÃ­as contarme sobre tu experiencia con React?

Candidato: Hola, gracias. Tengo 4 aÃ±os de experiencia con React. He trabajado principalmente con hooks, Redux para estado global, y recientemente con Next.js para SSR.

Entrevistador: Perfecto. Â¿CÃ³mo manejarÃ­as el estado en una aplicaciÃ³n compleja?

Candidato: Depende del caso. Para estado local uso useState o useReducer. Para estado global, prefiero Redux Toolkit con RTK Query para las API calls. TambiÃ©n he usado Zustand para casos mÃ¡s simples.

Entrevistador: Interesante. Â¿QuÃ© opinas sobre la optimizaciÃ³n de performance?

Candidato: Es crucial. Uso React.memo para componentes que no cambian frecuentemente, useMemo y useCallback para evitar re-renders innecesarios. TambiÃ©n implemento lazy loading para componentes pesados.

Entrevistador: Muy bien. Â¿Tienes preguntas sobre el puesto?

Candidato: SÃ­, Â¿quÃ© stack tecnolÃ³gico usan actualmente? Â¿Y cÃ³mo manejan el deployment?""",
                    "fecha": "2025-01-18T10:30:00",
                    "participantes": ["Entrevistador", "Candidato"],
                    "metadata": {
                        "tipo": "entrevista",
                        "duracion": "45min", 
                        "proyecto": "Recruitment",
                        "prioridad": "alta"
                    }
                }
            ]
        }

# FunciÃ³n de utilidad para testing
def test_dataset_loader():
    """Prueba el cargador de datasets."""
    loader = DatasetLoader()
    
    # Generar dataset de ejemplo
    dataset_ejemplo = loader.generar_dataset_ejemplo("testing_masivo")
    
    print("ğŸ§ª Testing Dataset Loader")
    print(f"ğŸ“Š Dataset generado: {dataset_ejemplo['dominio']}")
    print(f"ğŸ’¬ Conversaciones: {len(dataset_ejemplo['conversaciones'])}")
    
    # Validar formato
    es_valido, errores = loader.validar_formato(dataset_ejemplo)
    print(f"âœ… Formato vÃ¡lido: {es_valido}")
    
    if errores:
        print("âŒ Errores encontrados:")
        for error in errores:
            print(f"  - {error}")
    
    # Guardar ejemplo para testing manual
    import os
    os.makedirs("data/datasets", exist_ok=True)
    
    with open("data/datasets/ejemplo_reuniones.json", 'w', encoding='utf-8') as f:
        import json
        json.dump(dataset_ejemplo, f, ensure_ascii=False, indent=2)
    
    print("ğŸ’¾ Dataset de ejemplo guardado en: data/datasets/ejemplo_reuniones.json")
    
    return dataset_ejemplo

if __name__ == "__main__":
    test_dataset_loader()